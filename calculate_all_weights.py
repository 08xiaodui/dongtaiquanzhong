#!/usr/bin/env python3
"""
è®¡ç®—æ‰€æœ‰äººçš„åŠ¨æ€æƒé‡
åŸºäºä»»åŠ¡å¼•ç”¨å…³ç³»å’Œè¢«å¼•ç”¨æ¬¡æ•°ï¼Œè®¡ç®—æ¯ä¸ªç”¨æˆ·åœ¨æ•´ä¸ªé¡¹ç›®ä¸­çš„æƒé‡
"""

import argparse
import json
from decimal import Decimal
from pathlib import Path
from collections import defaultdict
from utils.csv_parser import parse_feishu_tasks_csv
from core.revenue_calculator import RevenueNode, RevenueEdge, RevenueGraph
import datetime as dt


def calculate_user_weights(csv_path: Path, save_debug: bool = False):
    """è®¡ç®—æ‰€æœ‰ç”¨æˆ·çš„åŠ¨æ€æƒé‡"""

    print("=" * 80)
    print("ğŸ“Š è®¡ç®—æ‰€æœ‰ç”¨æˆ·åŠ¨æ€æƒé‡")
    print("=" * 80)

    # Step 1: è§£æCSV
    print("\n[Step 1] è§£æCSV...")
    parsed = parse_feishu_tasks_csv(csv_path)
    print(f"  âœ“ è§£æå®Œæˆ: {len(parsed.nodes)} ä¸ªä»»åŠ¡, {len(parsed.citations)} æ¡å¼•ç”¨")

    # Step 2: æ„å»ºèŠ‚ç‚¹æ˜ å°„
    print("\n[Step 2] æ„å»ºèŠ‚ç‚¹æ˜ å°„...")
    node_map = {}
    for node in parsed.nodes:
        node_map[node.title] = RevenueNode(
            id=node.title,
            creator_id=node.executors[0] if node.executors else "æœªåˆ†é…",
            created_at=node.created_date or dt.date.today(),
            citation_count=sum(1 for c in parsed.citations if c.to_title == node.title),
            creativity_factor=Decimal("1.0"),
            propagation_rate=Decimal("0.3"),
        )
    print(f"  âœ“ åˆ›å»ºäº† {len(node_map)} ä¸ªèŠ‚ç‚¹")

    # Step 3: æ„å»ºå¼•ç”¨è¾¹
    print("\n[Step 3] æ„å»ºå¼•ç”¨è¾¹...")
    edges = []
    for citation in parsed.citations:
        if citation.from_title in node_map and citation.to_title in node_map:
            edges.append(RevenueEdge(
                from_node_id=citation.from_title,
                to_node_id=citation.to_title,
                weight=Decimal(str(citation.weight))
            ))
    print(f"  âœ“ åˆ›å»ºäº† {len(edges)} æ¡å¼•ç”¨è¾¹")

    # Step 4: è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„ä»»åŠ¡æƒé‡
    print("\n[Step 4] è®¡ç®—ç”¨æˆ·ä»»åŠ¡æƒé‡...")
    user_stats = defaultdict(lambda: {
        "task_count": 0,  # ä»»åŠ¡æ•°é‡
        "direct_citations": 0,  # ä½œä¸ºæ‰§è¡Œäººçš„ä»»åŠ¡è¢«å¼•ç”¨æ¬¡æ•°
        "total_citation_weight": Decimal("0"),  # æ€»å¼•ç”¨æƒé‡
        "tasks": []  # ä»»åŠ¡åˆ—è¡¨
    })

    for node in node_map.values():
        user = node.creator_id
        user_stats[user]["task_count"] += 1
        user_stats[user]["direct_citations"] += node.citation_count

        # è®¡ç®—è¯¥èŠ‚ç‚¹çš„æƒé‡è´¡çŒ®
        # æƒé‡ = è¢«å¼•ç”¨æ¬¡æ•° Ã— åˆ›é€ æ€§ç³»æ•° Ã— æ—¶é—´ä¼˜å…ˆç³»æ•°
        days_elapsed = (dt.date.today() - node.created_at).days
        time_priority = 1 / (1 + days_elapsed / 365)
        node_weight = Decimal(str(node.citation_count)) * node.creativity_factor * Decimal(str(time_priority))

        user_stats[user]["total_citation_weight"] += node_weight
        user_stats[user]["tasks"].append({
            "title": node.id,
            "citations": node.citation_count,
            "weight": float(node_weight)
        })

    print(f"  âœ“ ç»Ÿè®¡äº† {len(user_stats)} ä¸ªç”¨æˆ·")

    # Step 5: è®¡ç®—æ ‡å‡†åŒ–æƒé‡ï¼ˆå æ¯”ï¼‰
    print("\n[Step 5] è®¡ç®—æ ‡å‡†åŒ–æƒé‡...")
    total_weight = sum(stats["total_citation_weight"] for stats in user_stats.values())

    user_weights = []
    for user, stats in user_stats.items():
        weight = stats["total_citation_weight"]
        normalized_weight = float(weight / total_weight * 100) if total_weight > 0 else 0

        user_weights.append({
            "user": user,
            "task_count": stats["task_count"],
            "total_citations": stats["direct_citations"],
            "raw_weight": float(weight),
            "normalized_weight": normalized_weight,  # ç™¾åˆ†æ¯”
            "tasks": sorted(stats["tasks"], key=lambda x: x["weight"], reverse=True)[:5]  # åªä¿ç•™å‰5ä¸ªä»»åŠ¡
        })

    # æŒ‰æƒé‡æ’åº
    user_weights.sort(key=lambda x: x["normalized_weight"], reverse=True)

    # Step 6: è¾“å‡ºç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ç”¨æˆ·åŠ¨æ€æƒé‡æ’è¡Œæ¦œ")
    print("=" * 80)
    print(f"{'æ’å':>4} {'ç”¨æˆ·':^20} {'ä»»åŠ¡æ•°':>8} {'è¢«å¼•ç”¨':>8} {'æƒé‡å æ¯”':>12} {'æƒé‡å€¼':>12}")
    print("-" * 80)

    for i, item in enumerate(user_weights, 1):
        print(f"{i:4d} {item['user']:^20} {item['task_count']:8d} {item['total_citations']:8d} "
              f"{item['normalized_weight']:11.2f}% {item['raw_weight']:12.4f}")

    print("-" * 80)
    print(f"{'åˆè®¡':^24} {sum(u['task_count'] for u in user_weights):8d} "
          f"{sum(u['total_citations'] for u in user_weights):8d} "
          f"{sum(u['normalized_weight'] for u in user_weights):11.2f}%")

    # Step 7: ä¿å­˜è¯¦ç»†ç»“æœ
    output_data = {
        "summary": {
            "total_users": len(user_weights),
            "total_tasks": sum(u["task_count"] for u in user_weights),
            "total_citations": sum(u["total_citations"] for u in user_weights),
            "total_weight": float(total_weight)
        },
        "user_weights": user_weights
    }

    output_path = Path("logs/user_weights.json")
    output_path.parent.mkdir(exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

    # Step 8: æ˜¾ç¤ºTOP 5ç”¨æˆ·çš„è¯¦ç»†ä»»åŠ¡
    print("\n" + "=" * 80)
    print("ğŸ” TOP 5 ç”¨æˆ·çš„é‡è¦ä»»åŠ¡")
    print("=" * 80)

    for item in user_weights[:5]:
        if item["user"] == "æœªåˆ†é…":
            continue
        print(f"\nã€{item['user']}ã€‘æƒé‡å æ¯”: {item['normalized_weight']:.2f}%")
        for i, task in enumerate(item["tasks"][:3], 1):
            print(f"  {i}. {task['title'][:50]:50s} (è¢«å¼•ç”¨{task['citations']}æ¬¡, æƒé‡{task['weight']:.4f})")

    print("\n" + "=" * 80)
    print("âœ“ æƒé‡è®¡ç®—å®Œæˆï¼")
    print("=" * 80)

    return user_weights


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®¡ç®—æ‰€æœ‰ç”¨æˆ·çš„åŠ¨æ€æƒé‡")
    parser.add_argument("--csv", default="csv/08å°é˜Ÿç½‘ç«™V2é¡¹ç›®ç®¡ç†_ä»»åŠ¡ç®¡ç†.csv", help="CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--debug", action="store_true", help="ä¿å­˜è°ƒè¯•ä¿¡æ¯")
    args = parser.parse_args()

    calculate_user_weights(Path(args.csv), args.debug)
